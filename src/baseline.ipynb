{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create datasets, dataloaders, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS = \"imagenet\"\n",
    "N_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "  '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "  '''\n",
    "  \n",
    "  elapsed_rounded = int(round((elapsed))) # Round to the nearest second\n",
    "  return str(datetime.timedelta(seconds=elapsed_rounded)) # Format as hh:mm:ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, n_epochs=25):\n",
    "  '''\n",
    "    General function to train a model\n",
    "  '''\n",
    "\n",
    "  # Measure the total training time for the whole run\n",
    "  total_t0 = time.time()\n",
    "\n",
    "  best_model = model.state_dict()\n",
    "  best_acc = 0.0\n",
    "\n",
    "  for epoch_i in range(n_epochs):\n",
    "    print()\n",
    "    print('========== Epoch {:} / {:} =========='.format(epoch_i + 1, n_epochs))\n",
    "    \n",
    "    # Measure the training time for epoch\n",
    "    t0 = time.time()\n",
    "\n",
    "    best_model = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in [\"train\", \"val\"]:\n",
    "      if phase == \"train\":\n",
    "        print(\"Training...\")\n",
    "        model.train() # Set model to training mode\n",
    "      else:\n",
    "        print(\"Running Validation...\")\n",
    "        model.eval() # Set model to evaluate mode\n",
    "\n",
    "      run_loss = 0.0\n",
    "      run_corrects = 0\n",
    "\n",
    "      # Iterate over data\n",
    "      for inputs, labels in tqdm(dataloaders[phase]):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        # Track history if only in train\n",
    "        with torch.set_grad_enabled(phase == \"train\"):\n",
    "          outputs = model(inputs)\n",
    "          _, preds = torch.max(outputs, 1)\n",
    "          loss = criterion(outputs, labels)\n",
    "\n",
    "          # If in training phase, backward + optimize\n",
    "          if phase == \"train\":\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Statistics \n",
    "        run_loss += loss.item() * inputs.size(0)\n",
    "        run_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "      if phase == \"train\":\n",
    "        scheduler.step()\n",
    "\n",
    "      epoch_loss = run_loss / dataset_sizes[phase]\n",
    "      epoch_acc = run_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "      print(\"{:} Loss: {:.4f}\").format(\"Training\" if phase == \"train\" else \"Validation\", epoch_loss)\n",
    "      print(\"{:} Acc: {:.4f}\").format(\"Training\" if phase == \"train\" else \"Validation\", epoch_acc)\n",
    "\n",
    "      if phase == \"val\":\n",
    "        if epoch_acc > best_acc:\n",
    "          best_acc = epoch_acc\n",
    "          best_model = model.state_dict()\n",
    "        \n",
    "        print(\"Epoch took {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "      print()\n",
    "\n",
    "  print(\"Training complete!\")\n",
    "  print(\"Total training took {:}\".format(format_time(time.time() - total_t0)))\n",
    "  print(\"Best Acc: {:.4f}\".format(best_acc))\n",
    "\n",
    "  # Load best model\n",
    "  model.load_state_dict(best_model)\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def get_optimizer(model):\n",
    "  # Parameters of frozen layers will not be optimized\n",
    "  return optim.SGD(\n",
    "      params=list(filter(lambda p: p.requires_grad, model.parameters())), \n",
    "      lr=0.001, \n",
    "      momentum=0.9\n",
    "    )\n",
    "\n",
    "def get_scheduler(optimizer):\n",
    "  # Decay LR by a factor of 0.1 every 7 epochs\n",
    "  return optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet50(pretrained=WEIGHTS)\n",
    "\n",
    "for params in resnet.parameters(): \n",
    "  params.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "n_features = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(n_features, N_CLASSES)\n",
    "\n",
    "optimizer = get_optimizer(resnet)\n",
    "scheduler = get_scheduler(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add missing parameters\n",
    "# resnet = train_model(resnet, criterion, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = models.densenet121(pretrained=WEIGHTS)\n",
    "\n",
    "for params in densenet.parameters(): \n",
    "  params.requires_grad = False\n",
    "\n",
    "n_features = densenet.classifier.in_features\n",
    "densenet.classifier = nn.Linear(n_features, N_CLASSES)\n",
    "\n",
    "optimizer = get_optimizer(densenet)\n",
    "scheduler = get_scheduler(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add missing parameters\n",
    "# densenet = train_model(densenet, criterion, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = models.vgg16(pretrained=WEIGHTS)\n",
    "\n",
    "for params in resnet.parameters(): \n",
    "  params.requires_grad = False\n",
    "\n",
    "n_features = vgg.classifier[6].in_features\n",
    "features = list(vgg.classifier.children())[:-1]\n",
    "features.extend([nn.Linear(n_features, N_CLASSES)])\n",
    "vgg.classifier = nn.Sequential(*features)\n",
    "\n",
    "optimizer = get_optimizer(vgg)\n",
    "scheduler = get_scheduler(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add missing parameters\n",
    "# vgg = train_model(vgg, criterion, optimizer, scheduler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
